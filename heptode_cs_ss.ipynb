{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter channel index to analyze:5\n"
     ]
    }
   ],
   "source": [
    "chan_index = raw_input('Enter channel index to analyze:')\n",
    "# print('Enter Open Ephys data directory path:')\n",
    "# source_path = raw_input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_path = '../data/OpenEphys_data/2019-04-26/2019-04-26_12-03-55/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "t0 = time.time()\n",
    "import OpenEphys\n",
    "from kaveh.toolbox import common_avg_ref, butter_bandpass_filter\n",
    "import Kwik\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import scipy.signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_names = []\n",
    "for root, dirnames, filenames in os.walk(source_path):\n",
    "    for filename in filenames:\n",
    "        f_regex = re.compile(r\".*CH(\\d|\\d\\d)\\.continuous$\")\n",
    "        if f_regex.match(filename):\n",
    "            f_names = f_names + [os.path.join(root, filename)]\n",
    "f_names = np.array(f_names)\n",
    "chans = [int(f.split('.')[-2].split('_')[-1][2:]) for f in f_names]\n",
    "f_names = f_names[np.argsort(chans)] # now sorted by channel number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "chan_data = []\n",
    "for contact in range(7):\n",
    "    contact_reps = []\n",
    "    for i in range(contact*4, contact*4 + 4):\n",
    "        print('Reading {}...'.format(f_names[i]))\n",
    "        file_content = OpenEphys.load(f_names[i])\n",
    "        Fs = float(file_content['header']['sampleRate'])\n",
    "        signal_filtered = butter_bandpass_filter(file_content['data'], 300, 3000, Fs, order=2 )\n",
    "        contact_reps.append(signal_filtered)\n",
    "    contact_reps = np.array(contact_reps)\n",
    "    chan_data.append(np.mean(contact_reps, axis=0))\n",
    "    print('-----------------------------------------------')\n",
    "chan_data = np.array(chan_data)\n",
    "contact_reps = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_avg_ref(chan_data)\n",
    "chan_data = scipy.signal.detrend(chan_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kaveh.sorting.spikesorter import SimpleSpikeSorter\n",
    "dt = 1.0/Fs\n",
    "sss = SimpleSpikeSorter(chan_data[chan_index, :], dt)\n",
    "sss._pre_process()\n",
    "sss._detect_spikes_minibatch()\n",
    "sss._align_spikes()\n",
    "sss.cs_num_gmm_components = 5\n",
    "sss._cluster_spike_by_feature()\n",
    "sss._cs_post_process()\n",
    "print(sss.cs_indices.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clusters = 4\n",
    "\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "pre_time = 0.0005\n",
    "post_time = 0.005\n",
    "\n",
    "pre_index = int(np.round(pre_time/sss.dt))\n",
    "post_index = int(np.round(post_time/sss.dt))\n",
    "aligned_cs = np.array([sss.voltage[i - pre_index : i + post_index] for i in sss.cs_indices])\n",
    "\n",
    "import random\n",
    "\n",
    "ss_indices = np.setdiff1d(sss.spike_indices, sss.cs_indices)\n",
    "aligned_ss = np.array([sss.voltage[i - pre_index : i + post_index] for i in ss_indices[1:-2]])\n",
    "\n",
    "\n",
    "mean_ss = np.mean(aligned_ss[random.sample(range(0, aligned_ss.shape[0]), sss.cs_indices.size), ], axis=0)\n",
    "\n",
    "gmm = GaussianMixture(num_clusters, covariance_type = 'full').fit(aligned_cs)\n",
    "\n",
    "cluster_labels = gmm.predict(aligned_cs)\n",
    "\n",
    "clusters = []\n",
    "for cn in np.arange(num_clusters):\n",
    "    clusters.append(aligned_cs[np.where(cluster_labels == cn)])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot cluster means\n",
    "colors = plt.cm.nipy_spectral(np.linspace(0,1,num_clusters))\n",
    "legend_labels = []\n",
    "for cn in np.arange(num_clusters):\n",
    "    legend_labels.append('c{}({}) '.format(cn, clusters[cn].shape[0]))\n",
    "\n",
    "import gc\n",
    "gc.collect()\n",
    "plt.figure(figsize=(8,5))\n",
    "# ax2 = plt.subplot(122)\n",
    "for cn in np.arange(num_clusters):\n",
    "    plt.plot(np.mean(clusters[cn], axis=0), color = colors[cn], label = legend_labels[cn])\n",
    "plt.plot(mean_ss, '--', label = 'Mean SS({})'.format(aligned_ss.shape[0]))\n",
    "# plt.show()    \n",
    "plt.legend() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_input(\"Enter CS clusters (comma separated; example: 5,3,1): \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_to_pick = [int(c) for c in clusters_to_pick.split(',')]\n",
    "cs_indices_to_pick = []\n",
    "for cti in clusters_to_pick:\n",
    "    cs_indices_to_pick = np.union1d(cs_indices_to_pick, sss.cs_indices[np.where(cluster_labels == cti)])\n",
    "cs_indices = cs_indices_to_pick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time.time()\n",
    "print(t1-t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving detected CS and SS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CS_csv_filename = os.path.join(source_path, 'channel_{}.CS.csv'.format(chan_index))\n",
    "SS_csv_filename = os.path.join(source_path, 'channel_{}.SS.csv'.format(chan_index))\n",
    "\n",
    "import csv\n",
    "with open(CS_csv_filename, 'w+') as f:\n",
    "    print('writing {} ... '.format(CS_csv_filename))\n",
    "    f.seek(0)\n",
    "    csvwriter = csv.writer(f, delimiter = ',')\n",
    "    csvwriter.writerows(cs_indices.reshape(-1,1))\n",
    "    \n",
    "with open(SS_csv_filename, 'w+') as f:\n",
    "    print('writing {} ... '.format(SS_csv_filename))\n",
    "    f.seek(0)\n",
    "    csvwriter = csv.writer(f, delimiter = ',')\n",
    "    csvwriter.writerows(ss_indices.reshape(-1,1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
